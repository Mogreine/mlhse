{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1RVaqbjvDZy"
   },
   "source": [
    "# Деревья решений решают проблемы\n",
    "__Суммарное количество баллов: 10__\n",
    "\n",
    "__Решение отправлять на `ml.course.practice@gmail.com`__\n",
    "\n",
    "__Тема письма: `[ML][MS][HW08] <ФИ>`, где вместо `<ФИ>` указаны фамилия и имя__\n",
    "\n",
    "Вы уже знакомы с классификацией методом KNN. В этом задании предстоит реализовать другой метод классификации - дерево решений. \n",
    "\n",
    "Одной из его особенностей является возможность объяснить в человекочитаемой форме, почему мы отнесли объект к определенному классу. Эта особенность позволяет использовать деревья решений для создания систем, которые могут подсказывать специалистам, на что именно стоит обратить внимание при принятии решений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y09WWGt_vDZ0"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs, make_moons\n",
    "import numpy as np\n",
    "import pandas\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from typing import Callable, Union, NoReturn, Optional, Dict, Any, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzSUSK9uvDZ5"
   },
   "source": [
    "### Задание 1 (2 балла)\n",
    "Во время построения дерева решений нам потребуется определить, какой из предикатов лучше всего разбивает обучающую выборку. Есть два критерия, которые позволяют это сделать: критерий Джини и энтропийный критерий. Первый для подсчета информативности разбиения использует коэффициент Джини, второй - энтропию. Реализуйте подсчет этих коэффициентов, а так же подсчет информативности разбиения. \n",
    "\n",
    "#### Описание функций\n",
    "`gini(x)` считает коэффициент Джини для массива меток\n",
    "\n",
    "`entropy(x)` считает энтропию для массива меток\n",
    "\n",
    "`gain(left_y, right_y, criterion)` считает информативность разбиения массива меток на левую `left_y` и правую `right_y` части при помощи `criterion`, который задается функцией (не строкой)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9qPa-jocvDZ6"
   },
   "outputs": [],
   "source": [
    "def gini(x: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Считает коэффициент Джини для массива меток x.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def entropy(x: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Считает энтропию для массива меток x.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def gain(left_y: np.ndarray, right_y: np.ndarray, criterion: Callable) -> float:\n",
    "    \"\"\"\n",
    "    Считает информативность разбиения массива меток.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    left_y : np.ndarray\n",
    "        Левая часть разбиения.\n",
    "    right_y : np.ndarray\n",
    "        Правая часть разбиения.\n",
    "    criterion : Callable\n",
    "        Критерий разбиения.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FhuioPJIvDZ_"
   },
   "source": [
    "### Задание 2 (1 балл)\n",
    "Деревья решений имеют хорошую интерпретируемость, т.к. позволяют не только предсказать класс, но и объяснить, почему мы предсказали именно его. Например, мы можем его нарисовать. Чтобы сделать это, нам необходимо знать, как оно устроено внутри. Реализуйте классы, которые будут задавать структуру дерева. \n",
    "\n",
    "#### DecisionTreeLeaf\n",
    "Поля:\n",
    "1. `y` должно содержать класс, который встречается чаще всего среди элементов листа дерева\n",
    "\n",
    "#### DecisionTreeNode\n",
    "В данной домашней работе мы ограничемся порядковыми и количественными признаками, поэтому достаточно хранить измерение и значение признака, по которому разбиваем обучающую выборку.\n",
    "\n",
    "Поля:\n",
    "1. `split_dim` измерение, по которому разбиваем выборку\n",
    "2. `split_value` значение, по которому разбираем выборку\n",
    "3. `left` поддерево, отвечающее за случай `x[split_dim] < split_value`. Может быть `DecisionTreeNode` или `DecisionTreeLeaf`\n",
    "4. `right` поддерево, отвечающее за случай `x[split_dim] >= split_value`. Может быть `DecisionTreeNode` или `DecisionTreeLeaf`\n",
    "\n",
    "__Интерфейс классов можно и нужно менять при необходимости__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5iYe41QvDaA"
   },
   "outputs": [],
   "source": [
    "class DecisionTreeLeaf:\n",
    "    \"\"\"\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    y : dict\n",
    "        Словарь, отображающий метки в вероятность того, что объект, попавший в данный лист, принадлжит классу, соответствующиему метке \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.y = None\n",
    "        raise NotImplementedError()\n",
    "\n",
    "class DecisionTreeNode:\n",
    "    \"\"\"\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    split_dim : int\n",
    "        Измерение, по которому разбиваем выборку.\n",
    "    split_value : float\n",
    "        Значение, по которому разбираем выборку.\n",
    "    left : Union[DecisionTreeNode, DecisionTreeLeaf]\n",
    "        Поддерево, отвечающее за случай x[split_dim] < split_value.\n",
    "    right : Union[DecisionTreeNode, DecisionTreeLeaf]\n",
    "        Поддерево, отвечающее за случай x[split_dim] >= split_value. \n",
    "    \"\"\"\n",
    "    def __init__(self, split_dim: int, split_value: float, \n",
    "                 left: Union['DecisionTreeNode', DecisionTreeLeaf], \n",
    "                 right: Union['DecisionTreeNode', DecisionTreeLeaf]):\n",
    "        self.split_dim = s\n",
    "        self.split_value = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pZJMBQjvDaE"
   },
   "source": [
    "### Задание 3 (3 балла)\n",
    "Теперь перейдем к самому дереву решений. Реализуйте класс `DecisionTreeClassifier`.\n",
    "\n",
    "#### Описание методов\n",
    "`fit(X, y)` строит дерево решений по обучающей выборке.\n",
    "\n",
    "`predict_proba(X)` для каждого элемента из `X` возвращает словарь `dict`, состоящий из пар `(класс, вероятность)`\n",
    "\n",
    "#### Описание параметров конструктора\n",
    "`criterion=\"gini\"` - задает критерий, который будет использоваться при построении дерева. Возможные значения: `\"gini\"`, `\"entropy\"`.\n",
    "\n",
    "`max_depth=None` - ограничение глубины дерева. Если `None` - глубина не ограничена\n",
    "\n",
    "`min_samples_leaf=1` - минимальное количество элементов в каждом листе дерева.\n",
    "\n",
    "#### Описание полей\n",
    "`root` - корень дерева. Может быть `DecisionTreeNode` или `DecisionTreeLeaf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0YIQ9HXLvDaF"
   },
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    \"\"\"\n",
    "    Attributes\n",
    "    ----------\n",
    "    root : Union[DecisionTreeNode, DecisionTreeLeaf]\n",
    "        Корень дерева.\n",
    "\n",
    "    (можете добавлять в класс другие аттрибуты).\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, criterion : str = \"gini\", \n",
    "                 max_depth : Optional[int] = None, \n",
    "                 min_samples_leaf: int = 1):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        criterion : str\n",
    "            Задает критерий, который будет использоваться при построении дерева.\n",
    "            Возможные значения: \"gini\", \"entropy\".\n",
    "        max_depth : Optional[int]\n",
    "            Ограничение глубины дерева. Если None - глубина не ограничена.\n",
    "        min_samples_leaf : int\n",
    "            Минимальное количество элементов в каждом листе дерева.\n",
    "\n",
    "        \"\"\"\n",
    "        self.root = None\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> NoReturn:\n",
    "        \"\"\"\n",
    "        Строит дерево решений по обучающей выборке.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Обучающая выборка.\n",
    "        y : np.ndarray\n",
    "            Вектор меток классов.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def predict_proba(self, X: np.ndarray) ->  List[Dict[Any, float]]:\n",
    "        \"\"\"\n",
    "        Предсказывает вероятность классов для элементов из X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Элементы для предсказания.\n",
    "        \n",
    "        Return\n",
    "        ------\n",
    "        List[Dict[Any, float]]\n",
    "            Для каждого элемента из X возвращает словарь \n",
    "            {метка класса -> вероятность класса}.\n",
    "        \"\"\"\n",
    "        \n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def predict(self, X : np.ndarray) -> list:\n",
    "        \"\"\"\n",
    "        Предсказывает классы для элементов X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Элементы для предсказания.\n",
    "        \n",
    "        Return\n",
    "        ------\n",
    "        list\n",
    "            Вектор предсказанных меток для элементов X.\n",
    "        \"\"\"\n",
    "        proba = self.predict_proba(X)\n",
    "        return [max(p.keys(), key=lambda k: p[k]) for p in proba]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rk8Y-gNxvDaI"
   },
   "source": [
    "Построенное дерево можно нарисовать. Метод `draw_tree` рисует дерево и сохраняет его в указанный файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_yO7EjVvDaJ"
   },
   "outputs": [],
   "source": [
    "def tree_depth(tree_root):\n",
    "    if isinstance(tree_root, DecisionTreeNode):\n",
    "        return max(tree_depth(tree_root.left), tree_depth(tree_root.right)) + 1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def draw_tree_rec(tree_root, x_left, x_right, y):\n",
    "    x_center = (x_right - x_left) / 2 + x_left\n",
    "    if isinstance(tree_root, DecisionTreeNode):\n",
    "        x_center = (x_right - x_left) / 2 + x_left\n",
    "        x = draw_tree_rec(tree_root.left, x_left, x_center, y - 1)\n",
    "        plt.plot((x_center, x), (y - 0.1, y - 0.9), c=(0, 0, 0))\n",
    "        x = draw_tree_rec(tree_root.right, x_center, x_right, y - 1)\n",
    "        plt.plot((x_center, x), (y - 0.1, y - 0.9), c=(0, 0, 0))\n",
    "        plt.text(x_center, y, \"x[%i] < %f\" % (tree_root.split_dim, tree_root.split_value),\n",
    "                horizontalalignment='center')\n",
    "    else:\n",
    "        plt.text(x_center, y, str(tree_root.y),\n",
    "                horizontalalignment='center')\n",
    "    return x_center\n",
    "\n",
    "def draw_tree(tree, save_path=None):\n",
    "    td = tree_depth(tree.root)\n",
    "    plt.figure(figsize=(0.33 * 2 ** td, 2 * td))\n",
    "    plt.xlim(-1, 1)\n",
    "    plt.ylim(0.95, td + 0.05)\n",
    "    plt.axis('off')\n",
    "    draw_tree_rec(tree.root, -1, 1, td)\n",
    "    plt.tight_layout()\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LakJLFj-vDaN"
   },
   "source": [
    "Для двумерного набора данных дерево можно отобразить на плоскости с данными. Кроме того, как и для любого классификатора, для него можно построить roc-кривую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jHDsYU8yvDaN"
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_test, p_pred):\n",
    "    positive_samples = sum(1 for y in y_test if y == 0)\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    for w in np.arange(-0.01, 1.02, 0.01):\n",
    "        y_pred = [(0 if p.get(0, 0) > w else 1) for p in p_pred]\n",
    "        tpr.append(sum(1 for yp, yt in zip(y_pred, y_test) if yp == 0 and yt == 0) / positive_samples)\n",
    "        fpr.append(sum(1 for yp, yt in zip(y_pred, y_test) if yp == 0 and yt != 0) / (len(y_test) - positive_samples))\n",
    "    plt.figure(figsize = (7, 7))\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "    plt.xlabel(\"False positive rate\")\n",
    "    plt.ylabel(\"True positive rate\")\n",
    "    plt.xlim(-0.01, 1.01)\n",
    "    plt.ylim(-0.01, 1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def rectangle_bounds(bounds):\n",
    "    return ((bounds[0][0], bounds[0][0], bounds[0][1], bounds[0][1]), \n",
    "            (bounds[1][0], bounds[1][1], bounds[1][1], bounds[1][0]))\n",
    "\n",
    "def plot_2d_tree(tree_root, bounds, colors):\n",
    "    if isinstance(tree_root, DecisionTreeNode):\n",
    "        if tree_root.split_dim:\n",
    "            plot_2d_tree(tree_root.left, [bounds[0], [bounds[1][0], tree_root.split_value]], colors)\n",
    "            plot_2d_tree(tree_root.right, [bounds[0], [tree_root.split_value, bounds[1][1]]], colors)\n",
    "            plt.plot(bounds[0], (tree_root.split_value, tree_root.split_value), c=(0, 0, 0))\n",
    "        else:\n",
    "            plot_2d_tree(tree_root.left, [[bounds[0][0], tree_root.split_value], bounds[1]], colors)\n",
    "            plot_2d_tree(tree_root.right, [[tree_root.split_value, bounds[0][1]], bounds[1]], colors)\n",
    "            plt.plot((tree_root.split_value, tree_root.split_value), bounds[1], c=(0, 0, 0))\n",
    "    else:\n",
    "        x, y = rectangle_bounds(bounds)\n",
    "        plt.fill(x, y, c=colors[tree_root.y] + [0.2])\n",
    "\n",
    "def plot_2d(tree, X, y):\n",
    "    plt.figure(figsize=(9, 9))\n",
    "    colors = dict((c, list(np.random.random(3))) for c in np.unique(y))\n",
    "    bounds = list(zip(np.min(X, axis=0), np.max(X, axis=0)))\n",
    "    plt.xlim(*bounds[0])\n",
    "    plt.ylim(*bounds[1])\n",
    "    plot_2d_tree(tree.root, list(zip(np.min(X, axis=0), np.max(X, axis=0))), colors)\n",
    "    for c in np.unique(y):\n",
    "        plt.scatter(X[y==c, 0], X[y==c, 1], c=[colors[c]], label=c)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRBRASXfvDaS"
   },
   "source": [
    "Наконец, протестируем дерево решений на синтетических наборах данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LmlXZyv9vDaT"
   },
   "outputs": [],
   "source": [
    "noise = 0.35\n",
    "X, y = make_moons(1500, noise=noise)\n",
    "X_test, y_test = make_moons(200, noise=noise)\n",
    "tree = DecisionTreeClassifier(max_depth=5, min_samples_leaf=30)\n",
    "tree.fit(X, y)\n",
    "plot_2d(tree, X, y)\n",
    "plot_roc_curve(y_test, tree.predict_proba(X_test))\n",
    "draw_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DOKhy8ipvDaW"
   },
   "outputs": [],
   "source": [
    "X, y = make_blobs(1500, 2, centers=[[0, 0], [-2.5, 0], [3, 2], [1.5, -2.0]])\n",
    "tree = DecisionTreeClassifier(max_depth=5, min_samples_leaf=30)\n",
    "tree.fit(X, y)\n",
    "plot_2d(tree, X, y)\n",
    "draw_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTg5EawevDaZ"
   },
   "source": [
    "### Задание 4 (3 балла)\n",
    "У малоизвестной MMORPG Smash Art Online удалилась часть базы данных, а бэкапа не оказалось. Уволив сисадмина, тимлид начал думать, как проще и быстрее разрешить ситуацию. Оказалось, что в основном пострадала информация о классах персонажей, но зато часть внутриигровой статистики осталась нетронутой. Было решено не перезапускать игровой мир, а попробовать восстановить утерянные данные.\n",
    "\n",
    "Посчитав, что ручное восстановление классов персонажей было бы очень долгим и вызвало бы недовольство игроков, тимлид решил пригласить специалиста по машинному обучению, который смог бы восстановить большую часть данных автоматически. \n",
    "\n",
    "Ваша задача - построить дерево решений, которое как можно более точно восстанавливает класс персонажа. В этом вам поможет статистика персонажей, а так же сохранившаяся часть классов персонажей. Чтобы дерево было достаточно интерпретируемым, его высота должна быть не больше `6`.\n",
    "\n",
    "\n",
    "#### Оценка задания\n",
    "Баллы за это задание выставляются в зависимости от точности полученного классификатора на закрытой части выборки:\n",
    "1. __Точность > 50%__ - 1 балл - классификатор значительно облегчил команде игры задачу по восстановлению классов игроков. Тимлид доволен и, вероятно, захочет продолжить сотрудничество в дальнейшем\n",
    "2. __Точность > 85%__ - 3 балла - классификатор сделал большую часть работы. Довольный тимлид задумчиво чешет подбородок, а затем предлагает сотрудничество на постоянной основе\n",
    "\n",
    "__Важно: метки классов - названия, а не числа. Пусть так и остается.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-S38umi4vDaa"
   },
   "outputs": [],
   "source": [
    "def read_dataset(path):\n",
    "    dataframe = pandas.read_csv(path, header=1)\n",
    "    dataset = dataframe.values.tolist()\n",
    "    random.shuffle(dataset)\n",
    "    y = [row[0] for row in dataset]\n",
    "    X = [row[1:] for row in dataset]\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47RKP6WrvDae"
   },
   "outputs": [],
   "source": [
    "X, y = read_dataset(\"train.csv\")\n",
    "dtc = None  # DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URFxN1AuvDaj"
   },
   "source": [
    "### Задание 5 (1 балл)\n",
    "От игроков начали поступать жалобы на то, что класс их персонажа внезапно сменился. В таких случаях модераторы смотрят на данные персонажа и пытаются восстановить его класс сами. Для того, чтобы им было проще это сделать, нужно научиться для каждого персонажа объяснять, почему дерево решений присвоило персонажу именно такой класс.\n",
    "\n",
    "Реализуйте функцию `predict_explain(dtc, X)`. Для каждого элемента элемента набора данных `X` она должна вернуть пару из предсказанного класса и человекочетаемой строковой записи условий, благодаря которым был предсказан класс. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0RFkhVIvDak"
   },
   "outputs": [],
   "source": [
    "def predict_explain(dtc: DecisionTreeClassifier, X: np.ndarray):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zF8BlHQNvDan"
   },
   "outputs": [],
   "source": [
    "X, y = read_dataset(\"train.csv\")\n",
    "for pred_y, expl in predict_explain(dtc, X[:20]):\n",
    "    print(\"Class:\", pred_y)\n",
    "    print(\"Explanation:\", expl)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw08_task.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
