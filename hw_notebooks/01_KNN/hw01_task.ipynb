{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN, рак и спам\n",
    "__Суммарное количество баллов: 12__\n",
    "\n",
    "__Решение отправлять на `ml.course.practice@gmail.com`__\n",
    "\n",
    "__Тема письма: `[HSE][ML][MS][HW01] <ФИ>`, где вместо `<ФИ>` указаны фамилия и имя__\n",
    "\n",
    "В этом домашнем задании Вам предлагается при помощи классификации методом k ближайших соседей научиться отличать тип опухоли в организме, а так же определять сообщения со спамом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import copy\n",
    "import pandas\n",
    "from typing import NoReturn, Tuple, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1 (1 балл)\n",
    "Для начала работы нам необходимо научиться читать набор данных. Всего мы будем работать с двумя наборами данных.\n",
    "\n",
    "__Cancer.csv__ - выборка данных о пациентах с доброкачественными и злокачественными опухолями. Задача - научиться их отличать.\n",
    "\n",
    "__Spam.csv__ - набор данных большего размера. Он содержит некоторую статистику по сообщениям, а так же метку, является ли сообщение спамом. Задача - научиться автоматически отличать спам от обычных сообщений.\n",
    "\n",
    "Реализуйте методы `read_cancer_dataset` и `read_spam_dataset`. Каждый из них принимает на вход путь к набору данных и возвращает выборку `X` и соответствующие метки `y`. Набор данных должен быть упорядочен случайно, т.е. необходимо сделать shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cancer_dataset(path_to_csv: str) -> Tuple[np.array, np.array]:\n",
    "    \"\"\"\n",
    "     \n",
    "    Parameters\n",
    "    ----------\n",
    "    path_to_csv : str\n",
    "        Путь к cancer датасету.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : np.array\n",
    "        Матрица признаков опухолей.\n",
    "    y : np.array\n",
    "        Вектор бинарных меток, 1 соответствует доброкачественной опухоли (M), \n",
    "        0 --- злокачественной (B).\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def read_spam_dataset(path_to_csv: str) -> Tuple[np.array, np.array]:\n",
    "    \"\"\"\n",
    "     \n",
    "    Parameters\n",
    "    ----------\n",
    "    path_to_csv : str\n",
    "        Путь к spam датасету.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : np.array\n",
    "        Матрица признаков сообщений.\n",
    "    y : np.array\n",
    "        Вектор бинарных меток, \n",
    "        1 если сообщение содержит спам, 0 если не содержит.\n",
    "    \n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bb4a12281896>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mread_cancer_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cancer.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-d0baa2056f8f>\u001b[0m in \u001b[0;36mread_cancer_dataset\u001b[1;34m(path_to_csv)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \"\"\"\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_spam_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_to_csv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "read_cancer_dataset(\"cancer.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2  (1 балл)\n",
    "Начиная работать с данными, нам необходимо их предобработать и подготовить. В частности, нам необходимо разделить выборку на две: тренировочную и тестовую. Тренировочная выборка необходима для обучения алгоритма, а тестовая для проверки результатов обучения. Обычно используют коэффициент разделения `0.9`.\n",
    "\n",
    "Необходимо вернуть кортеж из `X_train`, `y_train`, `X_test` и `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X: np.array, y: np.array, ratio: float\n",
    "                     ) -> Tuple[np.array, np.array, np.array, np.array]:\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.array\n",
    "        Матрица признаков.\n",
    "    y : np.array\n",
    "        Вектор меток.\n",
    "    ratio : float\n",
    "        Коэффициент разделения.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_train : np.array\n",
    "        Матрица признаков для train выборки.\n",
    "    y_train : np.array\n",
    "        Вектор меток для train выборки.\n",
    "    X_test : np.array\n",
    "        Матрица признаков для test выборки.\n",
    "    y_test : np.array\n",
    "        Вектор меток для test выборки.\n",
    "\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3 (2 балла)\n",
    "Также прежде чем приступать к решению задачи, нам необходимо определиться с метриками, которые позволят нам оценить полученное решение. Для задач классификации мы можем использовать precision, recall и accuracy. Эти метрики считаются для каждого класса.\n",
    "\n",
    "Метод возвращает:\n",
    "\n",
    "* Вектор __Precision__, каждый из элементов которого равен значению метрики precision для соответствующего класса. \n",
    "\n",
    "* Вектор __Recall__, каждый из элементов которого равен значению метрики recall для соответствующего класса.\n",
    "\n",
    "* __Accuracy__ - число, которое равно отношению правильно классифицированных элементов выборке к размеру выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_recall_accuracy(y_pred: np.array, y_true: np.array) -> Tuple[np.array, np.array, float]:\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : np.array\n",
    "        Вектор классов, предсказанных моделью.\n",
    "    y_true : np.array\n",
    "        Вектор истинных классов.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    precision : np.array\n",
    "        Вектор с precision для каждого класса.\n",
    "    recall : np.array\n",
    "        Вектор с recall для каждого класса.\n",
    "    accuracy : float\n",
    "        Значение метрики accuracy (одно для всех классов).\n",
    "\n",
    "    \"\"\"\n",
    "    accuracy = np.count_nonzero(y_true == y_pred) / len(y_true)\n",
    "\n",
    "    classes = np.unique(y_true)\n",
    "    precision_arr, recall_arr = [], []\n",
    "    negative, positive = False, True\n",
    "\n",
    "    for cl in classes:\n",
    "        y_true_cl = y_true == cl\n",
    "        y_pred_cl = y_pred == cl\n",
    "\n",
    "        tp = np.count_nonzero(np.logical_and(y_pred_cl == positive, y_true_cl == positive))\n",
    "        tn = np.count_nonzero(np.logical_and(y_pred_cl == negative, y_true_cl == negative))\n",
    "        fp = np.count_nonzero(np.logical_and(y_pred_cl == positive, y_true_cl == negative))\n",
    "        fn = np.count_nonzero(np.logical_and(y_pred_cl == negative, y_true_cl == positive))\n",
    "\n",
    "        precision_arr.append(tp / (tp + fp))\n",
    "        recall_arr.append(tp / (tp + fn))\n",
    "\n",
    "    return np.array(precision_arr), np.array(recall_arr), accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, имея этот метод, мы можем построить кривые зависимости Precision, Recall и Accuracy от параметра `k`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall(X_train, y_train, X_test, y_test, max_k=30):\n",
    "    ks = list(range(1, max_k + 1))\n",
    "    classes = len(np.unique(list(y_train) + list(y_test)))\n",
    "    precisions = [[] for _ in range(classes)]\n",
    "    recalls = [[] for _ in range(classes)]\n",
    "    accuracies = []\n",
    "    for k in ks:\n",
    "        classifier = KNearest(k)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        precision, recall, acc = get_precision_recall_accuracy(y_pred, y_test)\n",
    "        for c in range(classes):\n",
    "            precisions[c].append(precision[c])\n",
    "            recalls[c].append(recall[c])\n",
    "        accuracies.append(acc)\n",
    "    def plot(x, ys, ylabel, legend=True):        \n",
    "        plt.figure(figsize = (12, 3))\n",
    "        plt.xlabel(\"K\")\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xlim(x[0], x[-1])\n",
    "        plt.ylim(np.min(ys)-0.01, np.max(ys)+0.01)\n",
    "        for cls, cls_y in enumerate(ys):\n",
    "            plt.plot(x, cls_y, label=\"Class \" + str(cls))\n",
    "        if legend:\n",
    "            plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    plot(ks, recalls, \"Recall\")\n",
    "    plot(ks, precisions, \"Precision\")\n",
    "    plot(ks, [accuracies], \"Accuracy\", legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также для оценки качества классификации построим __ROC-кривую__. Она отражает зависимость __True Positive Rate__ (TPR) от __False Positive Rate__ (FPR) для заранее фиксированного класса. Чем график выше побочной диагонали - тем лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(X_train, y_train, X_test, y_test, max_k=30):\n",
    "    positive_samples = sum(1 for y in y_test if y == 0)\n",
    "    ks = list(range(1, max_k + 1))\n",
    "    curves_tpr = []\n",
    "    curves_fpr = []\n",
    "    colors = []\n",
    "    for k in ks:\n",
    "        colors.append([k / ks[-1], 0, 1 - k / ks[-1]])\n",
    "        knearest = KNearest(k)\n",
    "        knearest.fit(X_train, y_train)\n",
    "        p_pred = [p[0] for p in knearest.predict_proba(X_test)]\n",
    "        tpr = []\n",
    "        fpr = []\n",
    "        for w in np.arange(-0.01, 1.02, 0.01):\n",
    "            y_pred = [(0 if p > w else 1) for p in p_pred]\n",
    "            tpr.append(sum(1 for yp, yt in zip(y_pred, y_test) if yp == 0 and yt == 0) / positive_samples)\n",
    "            fpr.append(sum(1 for yp, yt in zip(y_pred, y_test) if yp == 0 and yt != 0) / (len(y_test) - positive_samples))\n",
    "        curves_tpr.append(tpr)\n",
    "        curves_fpr.append(fpr)\n",
    "    plt.figure(figsize = (7, 7))\n",
    "    for tpr, fpr, c in zip(curves_tpr, curves_fpr, colors):\n",
    "        plt.plot(fpr, tpr, color=c)\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "    plt.xlabel(\"False positive rate\")\n",
    "    plt.ylabel(\"True positive rate\")\n",
    "    plt.xlim(-0.01, 1.01)\n",
    "    plt.ylim(-0.01, 1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4 (5 баллов)\n",
    "Теперь преступим к реализации классификатора. В этот раз будем использовать классификацию методом k средних. Поскольку основной решаемой задачий во время классификации этим методом является поиск ближайших соседей, а набор данных может быть достаточно большим, наивная реализация будет работать очень долго.\n",
    "\n",
    "Одним из способов решить эту проблему является __KD-дерево__. Оно позволяет значительно ускорить поиск ближайших соседей. Реализуйте построение KD-дерева и выполнение запросов на поиск k ближайших соседей.\n",
    "\n",
    "Метод `__init__` должен принимать на вход набор точек `X`, по которому будет строиться дерево, а так же размер листов `leaf_size` построенного дерева.\n",
    "\n",
    "Метод `query` должен принимать на вход набор точек `X`, для каждой из которых необходимо найти `k` ближайших соседей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KDTree:\n",
    "    def __init__(self, X: np.array, leaf_size: int = 40):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.array\n",
    "            Набор точек, по которому строится дерево.\n",
    "        leaf_size : int\n",
    "            Минимальный размер листа\n",
    "            (то есть, пока возможно, пространство разбивается на области, \n",
    "            в которых не меньше leaf_size точек).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"        \n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def query(self, X: np.array, k: int = 1) -> List[List]:\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.array\n",
    "            Набор точек, для которых нужно найти ближайших соседей.\n",
    "        k : int\n",
    "            Число ближайших соседей.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[list]\n",
    "            Список списков (длина каждого списка k): \n",
    "            индексы k ближайших соседей для всех точек из X.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку данная струкутра данных является сложной, ее стоит протестировать отдельно. Для этого проведем тестирование с небольшим набором случайных точек. Если после выполнение вывод пуст, то KD-дерево скорее всего работает правильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_closest(X_train, X_test, k):\n",
    "    result = []\n",
    "    for x0 in X_test:\n",
    "        bests = list(sorted([(i, np.linalg.norm(x - x0)) for i, x in enumerate(X_train)], key=lambda x: x[1]))\n",
    "        bests = [i for i, d in bests]\n",
    "        result.append(bests[:min(k, len(bests))])\n",
    "    return result    \n",
    "\n",
    "X_train = np.random.randn(100, 3)\n",
    "X_test = np.random.randn(10, 3)\n",
    "tree = KDTree(X_train, leaf_size=2)\n",
    "predicted = tree.query(X_test, k=4, return_distance=False)\n",
    "true = true_closest(X_train, X_test, k=4)\n",
    "\n",
    "if np.sum(np.abs(np.array(np.array(predicted).shape) - np.array(np.array(true).shape))) != 0:\n",
    "    print(\"Wrong shape\")\n",
    "else:\n",
    "    errors = sum([1 for row1, row2 in zip(predicted, true) for i1, i2 in zip(row1, row2) if i1 != i2])\n",
    "    if errors > 0:\n",
    "        print(\"Encounted\", errors, \"errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5  (3 балла)\n",
    "Осталось реализовать сам классификатор. Реализуйте его, используя KD-дерево.\n",
    "\n",
    "Метод `__init__` принимает на вход количество соседей, по которым предсказывается класс, и размер листьев KD-дерева.\n",
    "\n",
    "Метод `fit` должен по набору данных и меток строить классификатор. \n",
    "\n",
    "Метод `predict_proba` должен предсказывать веротности классов для заданного набора данных основываясь на классах соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearest:\n",
    "    def __init__(self, n_neighbors: int = 5, leaf_size: int = 30):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_neighbors : int\n",
    "            Число соседей, по которым предсказывается класс.\n",
    "        leaf_size : int\n",
    "            Минимальный размер листа в KD-дереве.\n",
    "\n",
    "        \"\"\"        \n",
    "        raise NotImplementedError()    \n",
    "    \n",
    "    def fit(self, X: np.array, y: np.array) -> NoReturn:\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.array\n",
    "            Набор точек, по которым строится классификатор.\n",
    "        y : np.array\n",
    "            Метки точек, по которым строится классификатор.\n",
    "\n",
    "        \"\"\"        \n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def predict_proba(self, X: np.array) -> List[np.array]:\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.array\n",
    "            Набор точек, для которых нужно определить класс.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list[np.array]\n",
    "            Список np.array (длина каждого np.array равна числу классов):\n",
    "            вероятности классов для каждой точки X.\n",
    "            \n",
    "\n",
    "        \"\"\"\n",
    "    \n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def predict(self, X: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.array\n",
    "            Набор точек, для которых нужно определить класс.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.array\n",
    "            Вектор предсказанных классов.\n",
    "            \n",
    "\n",
    "        \"\"\"\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, протестируем наш классификатор на различных наборах данных. Реализация KNearest должна отработать за разумное время."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X, y = read_cancer_dataset(\"cancer.csv\")\n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y, 0.9)\n",
    "plot_precision_recall(X_train, y_train, X_test, y_test)\n",
    "plot_roc_curve(X_train, y_train, X_test, y_test, max_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X, y = read_spam_dataset(\"spam.csv\")\n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y, 0.9)\n",
    "plot_precision_recall(X_train, y_train, X_test, y_test, max_k=20)\n",
    "plot_roc_curve(X_train, y_train, X_test, y_test, max_k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
